2025-12-22 20:08:23,045 INFO    MainThread:16992 [wandb_setup.py:_flush():80] Current SDK version is 0.23.1
2025-12-22 20:08:23,045 INFO    MainThread:16992 [wandb_setup.py:_flush():80] Configure stats pid to 16992
2025-12-22 20:08:23,045 INFO    MainThread:16992 [wandb_setup.py:_flush():80] Loading settings from C:\Users\Ishaan\.config\wandb\settings
2025-12-22 20:08:23,045 INFO    MainThread:16992 [wandb_setup.py:_flush():80] Loading settings from C:\Users\Ishaan\OneDrive\Desktop\Neo\wandb\settings
2025-12-22 20:08:23,045 INFO    MainThread:16992 [wandb_setup.py:_flush():80] Loading settings from environment variables
2025-12-22 20:08:23,045 INFO    MainThread:16992 [wandb_init.py:setup_run_log_directory():714] Logging user logs to C:\Users\Ishaan\OneDrive\Desktop\Neo\wandb\run-20251222_200823-4dk0z6xb\logs\debug.log
2025-12-22 20:08:23,046 INFO    MainThread:16992 [wandb_init.py:setup_run_log_directory():715] Logging internal logs to C:\Users\Ishaan\OneDrive\Desktop\Neo\wandb\run-20251222_200823-4dk0z6xb\logs\debug-internal.log
2025-12-22 20:08:23,048 INFO    MainThread:16992 [wandb_init.py:init():841] calling init triggers
2025-12-22 20:08:23,048 INFO    MainThread:16992 [wandb_init.py:init():846] wandb.init called with sweep_config: {}
config: {'ticker': 'BTC-USD', 'algorithm': 'RecurrentPPO', 'total_timesteps': 10000, '_wandb': {'code_path': 'code/neo.py'}}
2025-12-22 20:08:23,048 INFO    MainThread:16992 [wandb_init.py:init():889] starting backend
2025-12-22 20:08:25,387 INFO    MainThread:16992 [wandb_init.py:init():892] sending inform_init request
2025-12-22 20:08:25,410 INFO    MainThread:16992 [wandb_init.py:init():900] backend started and connected
2025-12-22 20:08:25,435 INFO    MainThread:16992 [wandb_init.py:init():970] updated telemetry
2025-12-22 20:08:25,436 INFO    MainThread:16992 [wandb_init.py:init():994] communicating run to backend with 90.0 second timeout
2025-12-22 20:08:26,041 INFO    MainThread:16992 [wandb_init.py:init():1041] starting run threads in backend
2025-12-22 20:08:26,315 INFO    MainThread:16992 [wandb_run.py:_console_start():2521] atexit reg
2025-12-22 20:08:26,315 INFO    MainThread:16992 [wandb_run.py:_redirect():2369] redirect: wrap_raw
2025-12-22 20:08:26,315 INFO    MainThread:16992 [wandb_run.py:_redirect():2438] Wrapping output streams.
2025-12-22 20:08:26,315 INFO    MainThread:16992 [wandb_run.py:_redirect():2461] Redirects installed.
2025-12-22 20:08:26,319 INFO    MainThread:16992 [wandb_init.py:init():1081] run started, returning control to user process
2025-12-22 20:08:27,563 INFO    MainThread:16992 [wandb_run.py:_config_callback():1396] config_cb None None {'algo': 'RecurrentPPO', 'policy_class': "<class 'sb3_contrib.common.recurrent.policies.RecurrentActorCriticPolicy'>", 'device': 'cpu', 'verbose': 1, 'policy_kwargs': "{'net_arch': [128, 128]}", 'num_timesteps': 0, '_total_timesteps': 10000, '_num_timesteps_at_start': 0, 'seed': 'None', 'action_noise': 'None', 'start_time': 1766455707556395200, 'learning_rate': 0.0003, 'tensorboard_log': 'None', '_last_obs': '[[ 0.00999998  0.00999998  0.00999998  0.00999998  0.01        0.00999997\n   0.00999996  0.00999995  0.00999566 -0.00998444 -0.00991598  0.00976719\n   0.00999998  0.00999995  0.00999974  0.          0.01       -0.00999981\n  -0.00074429 -0.00074429 -0.00074429 -0.00074429 -0.00074429  0.00048498\n   0.00041614  0.00707071  0.00707071  0.          0.          0.        ]]', '_last_episode_starts': '[ True]', '_last_original_obs': '[[ 4.6586401e+02  4.6817401e+02  4.5242200e+02  4.5733401e+02\n   2.1056800e+07  3.8991040e+02  3.7276685e+02  3.1084317e+02\n   3.3933723e+01 -1.7904762e+01 -7.6662312e+00  4.5534296e+00\n   4.5922699e+02  3.2059381e+02  1.3863321e+02  0.0000000e+00\n   2.1056800e+07 -1.6312064e+02 -7.4643351e-02 -7.4643351e-02\n  -7.4643351e-02 -7.4643351e-02 -7.4643351e-02  4.8559781e-02\n   4.1653823e-02  1.0000000e+00  1.0000000e+00  0.0000000e+00\n   0.0000000e+00  0.0000000e+00]]', '_episode_num': 0, 'use_sde': 'False', 'sde_sample_freq': -1, '_current_progress_remaining': 1.0, '_stats_window_size': 100, 'ep_info_buffer': 'deque([], maxlen=100)', 'ep_success_buffer': 'deque([], maxlen=100)', '_n_updates': 0, '_custom_logger': 'False', 'env': '<stable_baselines3.common.vec_env.vec_normalize.VecNormalize object at 0x0000019052A68EC0>', '_vec_normalize_env': '<stable_baselines3.common.vec_env.vec_normalize.VecNormalize object at 0x0000019052A68EC0>', 'observation_space': 'Box(-inf, inf, (30,), float32)', 'action_space': 'Discrete(3)', 'n_envs': 1, 'n_steps': 128, 'gamma': 0.99, 'gae_lambda': 0.95, 'ent_coef': 0.01, 'vf_coef': 0.5, 'max_grad_norm': 0.5, 'rollout_buffer_class': 'None', 'rollout_buffer_kwargs': '{}', 'batch_size': 64, 'n_epochs': 10, 'clip_range': 'FloatSchedule(ConstantSchedule(val=0.2))', 'clip_range_vf': 'None', 'normalize_advantage': 'True', 'target_kl': 'None', '_last_lstm_states': 'RNNStates(pi=(tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0.]]]), tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0.]]])), vf=(tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0.]]]), tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0.]]])))', 'lr_schedule': 'FloatSchedule(ConstantSchedule(val=0.0003))', 'policy': 'RecurrentActorCriticPolicy(\n  (features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (pi_features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (vf_features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (mlp_extractor): MlpExtractor(\n    (policy_net): Sequential(\n      (0): Linear(in_features=256, out_features=128, bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=128, out_features=128, bias=True)\n      (3): Tanh()\n    )\n    (value_net): Sequential(\n      (0): Linear(in_features=256, out_features=128, bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=128, out_features=128, bias=True)\n      (3): Tanh()\n    )\n  )\n  (action_net): Linear(in_features=128, out_features=3, bias=True)\n  (value_net): Linear(in_features=128, out_features=1, bias=True)\n  (lstm_actor): LSTM(30, 256)\n  (lstm_critic): LSTM(30, 256)\n)', 'rollout_buffer': '<sb3_contrib.common.recurrent.buffers.RecurrentRolloutBuffer object at 0x0000019055085EB0>', '_logger': '<stable_baselines3.common.logger.Logger object at 0x00000190574EA150>'}
2025-12-22 20:08:56,957 INFO    MainThread:16992 [wandb_run.py:_finish():2287] finishing run meridianalgo-meridianalgo/neo-v4/4dk0z6xb
2025-12-22 20:08:56,957 INFO    MainThread:16992 [wandb_run.py:_atexit_cleanup():2486] got exitcode: 0
2025-12-22 20:08:56,958 INFO    MainThread:16992 [wandb_run.py:_restore():2468] restore
2025-12-22 20:08:56,958 INFO    MainThread:16992 [wandb_run.py:_restore():2474] restore done
2025-12-22 20:08:57,708 INFO    MainThread:16992 [wandb_run.py:_footer_sync_info():3862] logging synced files
